#! /usr/bin/env python3

# -----------------------------------------------------------------------------
# (C) Crown copyright Met Office. All rights reserved.
# The file LICENCE, distributed with this code, contains details of the terms
# under which the code may be used.
# -----------------------------------------------------------------------------

import os
import xarray as xr
import numpy as np

"""
Script to generate a simple dataset for testing mean_nemo

Two types of files will be generated- input data (intended as input to mean_nemo) and expected results 
(the results expected from running mean_nemo with the input data). The following `nccmp` command is recommended
for comparing the latter file with the output from mean_nemo:

    `nccmp -F -f -c 1 -d -m <mean_nemo_output_file> <expected_results_file>`
    
The expected results are obtained by using xarray/numpy averaging methods.
    
Both types of file will contain several variables that test different components of the mean_nemo code, named:

    {data_type}_{data_shape}_{weighting}_{time_coordinate}_{masking}
    
where:

    * `data_type`- the data precision, using their numpy alias names ("byte", "short", "intc", "single", "double")
    * `data_shape`- the shape of the data ("1d", "2d", "3d", "4d")
    * `weighting`- the weighting method used in the average:
        * "unweighted"- no weighting is used
        * "weighted"- the average is weighted by an unmasked cell thickness
        * "weighted-masked"- the average is weighted by a masked cell thickness
    * `time_coordinate`- whether the data has a time coordinate ("time") or not ("notime")
    * `masking`- whether the data is masked ("masked") or not ("unmasked")
"""

# User input
# ============================================================================================================================

# Paths for files generated by this script
dir_out = ''                                                            # Output directory
file_out = f'{dir_out}/input.nc'                                        # Input data (unmasked cell thickness)
file_out_cellthk_masked = f'{dir_out}/input_cellthk_masked.nc'          # Input data (masked cell thickness)
file_expected = f'{dir_out}/expected.nc'                                # Expected results (unmasked cell thickness)
file_expected_cellthk_masked = f'{dir_out}/expected_cellthk_masked.nc'  # Expected results (masked cell thickness)

# Properties of the test data
data_dims = ('t', 'b', 'z', 'y', 'x')                       # Order of dimensions in the file
data_shape = {'t': 6, 'x': 10, 'y': 10, 'z': 10, 'b': 5}    # Shape of the FULL test data (sliced by data_isel entries
                                                            # to generate the different data shapes)
data_time_split = [slice(0, 2), slice(2, 4), slice(4, 6)]   # How data should be split in time between files
data_masked_isel = [                                        # Points to be masked in the FULL test data
    {'x': [2, 4], 'y': [2, 4, 6]},
    {'z': [7, 8, 9]},
    {'t': [0], 'x': [0], 'y': [0], 'z': [0]},
    {'t': [2], 'x': [1], 'y': [0], 'z': [0]},
    {'t': [4], 'x': [1], 'y': [1], 'z': [0]},
    {'t': [2, 4], 'b': [3], 'x': [2]},
    ]
cellthk_masked_isel = [                                     # Points to be masked in the FULL cell thickness data
    {'x': [2], 'y': [4]},
    {'t': [0], 'x': [0], 'y': [1, 3, 5]},
    {'t': [3], 'x': [1], 'y': [1, 3, 5]},
    {'t': [5], 'x': [2], 'y': [1, 3, 5]},
    ]
data_isel = {                                               # Data shapes to be generated and the coordinates
    '1d': {'b': 0, 'z': 0, 'y': 0, 'x': 0},                 # used to generate them with respect to the FULL data
    '2d': {'b': 0, 'z': 0, 'y': 0},
    '3d': {'b': 0, 'z': 0},
    '4d': {'b': 0},
    '5d': None,
    }
data_fillvals = {                                           # Data types to be generated and the fill values
    'byte': -1,                                             # to be used for masked data
    'short': -1,
    'intc': -1,
    'single': 1e20,
    'double': 1e20,
    }

# ============================================================================================================================

# Numpy data type objects
data_dtypes = {i: getattr(np, i) for i in data_fillvals}

# Dimensions
dict_da_dims = {k: xr.DataArray(range(v), dims=k) for k, v in data_shape.items()}

# Full test data (double precision)- linear increase over each dimension
data_full = np.mgrid[*[slice(None, data_shape[i]) for i in data_dims]].sum(axis=0).astype('double')
da_full = xr.DataArray(data_full,
                       coords=[dict_da_dims[i] for i in data_dims])

# Mask for full test data (True where valid)
da_isvalid_full = xr.DataArray(True, coords=[dict_da_dims[i] for i in data_dims])
for isel in data_masked_isel:
    da_isvalid_full[isel] = False

# Full cell thickness data (single precision)- linear increase with time
da_cellthk_full = xr.DataArray(0,
                               coords=[dict_da_dims[i] for i in ('t', 'z', 'y', 'x')],
                               attrs={'standard_name': 'cell_thickness'},
                               name='cellthk').astype('single')
da_cellthk_full += da_cellthk_full.t + 1

# Mask for full cell thickness data (True where valid)
da_cellthk_isvalid_full = xr.DataArray(True, coords=[dict_da_dims[i] for i in ('t', 'z', 'y', 'x')])
for isel in cellthk_masked_isel:
    da_cellthk_isvalid_full[isel] = False

# DataArray lists to be combined into Datasets later
da_list = []
da_list_cellthk_masked = []
da_expected_list = []
da_expected_list_cellthk_masked = []


def input_data(da: xr.DataArray, da_isvalid: xr.DataArray | None,
               dtype: np.dtype, slices: dict | None, fillval: np.typing.ArrayLike,
               drop_time_coord: bool = False, is_weighted: bool = False, masked_in_file: bool = False
               ) -> (xr.DataArray, xr.DataArray | None):
    """
    Generate input data.

    Parameters
    ----------
    da : xr.DataArray
        Full input data to use as the basis
    da_isvalid : xr.DataArray | None
        Mask to apply to `da` (`False` where masked)
    dtype : np.dtype
        Numpy dtype to convert `da` to
    slices : dict | None
        Indexing slices to apply to `da`
    fillval : np.typing.ArrayLike
        Value to set when applying `da_isvalid` mask
    drop_time_coord : bool
        Whether the time coordinate should be dropped from `da`
    is_weighted : bool
        Whether a `cell_methods` attribute will be applied to `da` to indicate it is weighted by the cell thickness
    masked_in_file : bool
        Whether a `_FillValue` attribute will be applied to `da`

    Returns
    -------
    da : xr.DataArray
        Input data
    xr.DataArray | None
        `masked_in_file == True:`
            Input data mask (`True` where valid) corresponding to `da`
        `masked_in_file == False`:
            None
    """
    # Slice full data and mask
    if slices is not None:
        da = da.isel(**slices, drop=True)
        da_isvalid = da_isvalid.isel(**slices, drop=True)

    # Convert to given data type
    da = da.astype(dtype)

    # Set masked data to given fill value (np.nan not representable for non-floats)
    da = da.where(da_isvalid, fillval)

    # No time coordinate- use first time and drop coordinate
    if drop_time_coord:
        da = da.isel(t=0, drop=True)

    # Thickness-weighting- assign cell_methods recognised by mean_nemo
    if is_weighted:
        da = da.assign_attrs(cell_methods='time: mean (thickness weighted)')

    # Set _FillValue if data is to be read in as masked by mean_nemo
    da.encoding = {'_FillValue': fillval if masked_in_file else None}

    return da, (da_isvalid if masked_in_file else None)


def cellthk_data(da: xr.DataArray, slices: dict | None = None, da_isvalid: xr.DataArray | None = None
                 ) -> xr.DataArray:
    """
    Generate cell thickness data.

    Parameters
    ----------
    da : xr.DataArray
        Full cell thickness data to use as the basis
    slices : dict | None
        Indexing slices to apply to `da`
    da_isvalid : xr.DataArray | None
        Mask to apply to `da` (`False` where masked)

    Returns
    -------
    da: xr.DataArray
        Cell thickness data
    """
    # If data will be masked, set masked points to np.nan and set a _FillValue for these points to be written to file
    if da_isvalid is not None:
        da = da.where(da_isvalid)
        da.encoding = {'_FillValue': np.single(2e20)}
    else:
        da.encoding = {'_FillValue': None}

    # Slice full data
    if slices is not None:
        da = da.isel(**slices, drop=True, missing_dims='ignore')

    return da


def calc_mean(da: xr.DataArray, da_isvalid: xr.DataArray | None = None, da_cellthk: xr.DataArray | None = None
              ) -> xr.DataArray:
    """
    Calculate the time-average (i.e. the expected result) using xarray/numpy routines.

    Parameters
    ----------
    da : xr.DataArray
        Data to be averaged
    da_isvalid : xr.DataArray | None
        Mask to apply to `da` for the average (`False` where masked)
    da_cellthk : xr.DataArray | None
        Weighting to apply to `da` for the average (`np.nan` where masked)

    Returns
    -------
    da: xr.DataArray
        Time average of `da`
    """
    dtype = da.dtype
    fillval = da.encoding['_FillValue']
    attrs = da.attrs

    # Time coordinate to be added to average data
    t_mean = da.t.mean().astype(np.intc).expand_dims('t')

    # Thickness-weighting
    if da_cellthk is not None:

        # When the input data has no fill value, use the cell thickness fill value instead
        if fillval is None:
            fillval = da_cellthk.encoding['_FillValue']

        # Set masked cell thickness data to 0 (exclude from weighted average- np.nan not allowed)
        da_cellthk = da_cellthk.fillna(0)

    # Masked averaging
    if da_isvalid is not None:

        # We can use the normal masking-aware aggregators for floats, which support np.nan
        if dtype in (np.single, np.double):
            if da_cellthk is not None:
                da = da.where(da_isvalid.values).weighted(da_cellthk).mean('t')
            else:
                da = da.where(da_isvalid.values).mean('t')

        # Otherwise, we have to pass a `where` argument since np.nan isn't correctly represented for non-floats
        else:
            da = da.mean('t', where=da_isvalid.values, skipna=False)

            # The mean results in zeroes where there is no data over time, so we must restore the fill values
            da = da.where(da_isvalid.any('t'), fillval)

    # Normal averaging
    else:
        if da_cellthk is not None:

            # The weighted mean will contain np.nan where there is no data, but this isn't supported for non-floats.
            # Stop so we can see what needs to be done.
            if dtype not in (np.single, np.double):
                raise TypeError(f'Weighted unmasked average not supported for non-floats')

            da = da.weighted(da_cellthk).mean('t')
        else:
            da = da.mean('t')

    # Recast the result back to the original precision
    da = da.astype(dtype)

    # Restore _FillValue and other attributes (averaging removes them)
    da.encoding = {'_FillValue': fillval}
    da = da.assign_attrs(**attrs)

    # Assign a time coordinate (dropped by averaging)- use an unweighted average since this is what mean_nemo does
    da = da.expand_dims('t').assign_coords(t=t_mean)

    return da


# Generate data for each of the:
# Data types
for dtype_name in data_dtypes:
    # Data shapes
    for shape_name in data_isel:
        # Data to be used in thickness-weighted (where cell thickness is masked or unmasked) or normal averages
        for thk_name in ('unweighted', 'weighted', 'weighted-masked'):
            # Data with/without a time coordinate
            for time_name in ('time', 'notime'):
                # Data that will be read in by mean_nemo as masked or unmasked
                for mask_name in ('masked', 'unmasked'):

                    dtype = data_dtypes[dtype_name]
                    fillval = dtype(data_fillvals[dtype_name])
                    slices = data_isel[shape_name]

                    # Skip thickness-weighted cases not supported by mean_nemo
                    if (thk_name.startswith('weighted') and
                            not (time_name == 'time' and shape_name in ('4d',) and dtype in (np.single, np.double))):
                        continue
                    # Skip scalars, which aren't supported by mean_nemo
                    if (time_name == 'notime') and (shape_name == '1d'):
                        continue
                    # Skip masked cases not supported by mean_nemo
                    if (mask_name == 'masked') and not (shape_name in ('3d', '4d', '5d') and
                                                        dtype in (np.intc, np.single, np.double)):
                        continue

                    # Get input data and its mask
                    da_input, da_isvalid = input_data(da_full, da_isvalid_full, dtype, slices, fillval,
                                                      drop_time_coord=(time_name == 'notime'),
                                                      is_weighted=(thk_name.startswith('weighted')),
                                                      masked_in_file=(mask_name == 'masked'),
                                                      )

                    # Variable name
                    da_input.name = f'{dtype_name}_{shape_name}_{thk_name}_{time_name}_{mask_name}'

                    # Get the cell thickness if required for thickness-weighting
                    if thk_name.startswith('weighted'):
                        da_cellthk = cellthk_data(da_cellthk_full, slices=slices,
                                                  da_isvalid=(da_cellthk_isvalid_full if thk_name == 'weighted-masked' else None),
                                                  )
                    else:
                        da_cellthk = None

                    # Calculate the expected result
                    if time_name == 'time':
                        da_expected = calc_mean(da_input, da_isvalid=da_isvalid, da_cellthk=da_cellthk)
                    else:
                        da_expected = da_input

                    # We can only have one cell thickness variable per file (mean_nemo limitation)-
                    # put the cell thickness and the variables weighted by it in separate files
                    if thk_name == 'weighted-masked':
                        da_list_cellthk_masked.append(da_input)
                        da_expected_list_cellthk_masked.append(da_expected)
                    else:
                        da_list.append(da_input)
                        da_expected_list.append(da_expected)

# Add unmasked cell thickness to data
da_cellthk = cellthk_data(da_cellthk_full)
da_expected = calc_mean(da_cellthk)
da_list.append(da_cellthk)
da_expected_list.append(da_expected)

# Add masked cell thickness to data
da_cellthk = cellthk_data(da_cellthk_full, da_isvalid=da_cellthk_isvalid_full)
da_expected = calc_mean(da_cellthk)
da_list_cellthk_masked.append(da_cellthk)
da_expected_list_cellthk_masked.append(da_expected)

# Combine DataArrays to Datasets
ds_out = xr.merge(da_list)
ds_out_cellthk_masked = xr.merge(da_list_cellthk_masked)
ds_expected = xr.merge(da_expected_list)
ds_expected_cellthk_masked = xr.merge(da_expected_list_cellthk_masked)

# Create output directory if needed
if not os.path.isdir(dir_out):
    os.makedirs(dir_out)

# Write input data to files- potentially split over multiple files (file_0.nc, file_1.nc, etc)
for i_file, time_slice in enumerate(data_time_split):
    fname = f'{file_out.replace('.nc', '')}_{i_file}.nc'
    ds_out.isel(t=time_slice).to_netcdf(fname, mode='w', format='NETCDF4_CLASSIC', unlimited_dims=['t'])
    fname = f'{file_out_cellthk_masked.replace('.nc', '')}_{i_file}.nc'
    ds_out_cellthk_masked.isel(t=time_slice).to_netcdf(fname, mode='w', format='NETCDF4_CLASSIC', unlimited_dims=['t'])

# Write expected results to files- currently NC3 with 64-bit offset
ds_expected.to_netcdf(file_expected, mode='w', format='NETCDF3_64BIT', unlimited_dims=['t'])
ds_expected_cellthk_masked.to_netcdf(file_expected_cellthk_masked, mode='w', format='NETCDF3_64BIT', unlimited_dims=['t'])
